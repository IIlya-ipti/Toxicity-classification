токенайзер заменяет последовательность слов на индекс в словаре
Чем чаще слово попадается, тем меньше его индекс

token.texts_to_sequences - заменяет предложение на массив индексов в словаре ['the of'] -> [0,1]
pad_sequences - дополняет нулями последовательность до maxlen [1,2,3] -> [0,0,0,1,2,3]
